---
title: "RProject"
author: "Amy Lang(S2127213), Chen Yu Qi (17068721), Yeoh Li Tian(s2120306), Puveemalr Parameswaran(s2127371), Qi Han(s2123517)"
date: "6/5/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction(Puvee)
In the context of expanding urbanisation and industrialisation, air quality monitoring and prediction are becoming more relevant research subjects. As a result, effective air quality parameter modelling is critical since it allows for the identification of current and future air pollution consequences. In recent years, India has been the world's top 5 most polluted country with 58.1 Air Quality Index(AQI) in 2022 due to a dramatic increase in air pollution levels. Hence, the data set regarding Air Quality in India collected from 2015-2020 is been analysed to display the city with lowest air quality among the cities of India.In this data set the air quality has been tested with 7 types of air pollutant which are Particulate Matter (PM2.5), Particulate Matter(PM10), Nitrogen Dioxide(NO2), Ammonia(NH3), Sulphur Dioxide(SO2), Carbon Monoxide(CO) and Ozone(O3).

# Objective(Puvee)

1. To describe the history of movement of air air pollutant with time.
2. To develop clustering which is unsupervised machine learning technique to identify cities (location) with similar air quality.
3. To develop a time series regression model for prediction.

# Data Preprocessing with Exploratory Data Analysis (EDA)
## Load Libraries
```{r import library, message=FALSE}
library(ggplot2)
library(dplyr)
library(scales)
library(grid)
library(tidyr)
library(rstudioapi)
library(tidyverse)
library(lubridate,magrittr)
library(ggfortify)
library(tseries)
library('vars')
library('quantmod')
#library(LINselect)
library(forecast)
```

## Load Dataset
YLT: I changed this part, now u can just run and the path is set automatically
```{r load dataset}
main_dir<- dirname(dirname(rstudioapi::getSourceEditorContext()$path))
datadir<- paste0(main_dir,"/data")
data_path<- paste0(datadir,"/data.csv")

df=read.csv(data_path)
head(df)
```

## Explore Dataset
```{r data set characteristics}
str(df)
```
There are 13 variables and 435742 row of observations in total.

```{r data set characteristics1}
summary(df)
```
Stn_code, sampling_date, state, location, agency, type, location_monitoring_station and date is labelled as character variables.

so2,no2,rspm,spm and pm2_5 are numerical variables with missing values.


## Drop Unnecessary Variables

Since "sampling_date" carry same meaning as "date", we may drop it. 

stn_code, location, agency and location_monitoring_station also seen carry same meaning with state, we may drop it too.
```{r drop sampling_date}
df$sampling_date=NULL
df$stn_code=NULL
df$agency=NULL
df$location_monitoring_station=NULL
head(df)
```


## Exploratary Data Analysis - Univariate  

Let's observe the other variables one by one. 

### Categorical variable - State
```{r plot state}
plotdata <- df %>%
  count(state) %>%
  mutate(pct = n / sum(n),
         pctlabel = paste0(round(pct*100), "%"))
ggplot(plotdata, aes(x=reorder(state, n),y=pct)) +
  geom_bar(stat = "identity", fill = "lightgreen") +
  geom_text(aes(label = pctlabel), vjust = -0.25) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_y_continuous(labels = percent) +
  labs(y = "Percentage",x="State", title = "Percentage of Recording From Each State")

```

Maharashtra have most observations followed by Uttar Pradesh and others. 

### Categorical variable - Location
```{r plot location}
plotdata <- df %>%
  count(location) %>%
  mutate(pct = n / sum(n),
         pctlabel = paste0(round(pct*100), "%")) %>%
  arrange(desc(n)) %>%
  head(10)
ggplot(plotdata, aes(x = reorder(location, n),y=pct)) +
  geom_bar(stat = "identity", fill = "lightgreen") +
  geom_text(aes(label = pctlabel), vjust = -0.25) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  scale_y_continuous(labels = percent) +
  labs(y = "Percentage", title = "Percentage of Recording From Each Location")
```

Top 10 recording location is displayed. Guwahati have the highest percentage of recording. 


### Categorical Variable - Type
```{r plot Type}
plotdata <- df %>%
  count(type) %>%
  mutate(pct = n / sum(n),
         pctlabel = paste0(round(pct*100), "%"))
ggplot(plotdata, aes(x = reorder(type, n), y=pct)) +
  geom_bar(stat = "identity", fill = "lightgreen") +
  geom_text(aes(label = pctlabel), vjust = -0.25) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_y_continuous(labels = percent) +
  labs(y = "Percentage", x="Area Type", title = "Percentage of Recording From Each Type of Area")
```

We can group the data into "residual", "industrial" and "others" class. 

```{r plot Type1}
df$type[df$type %in% "Residential, Rural and other Areas"] <- "Residential"
df$type[df$type %in% "Residential and others"] <- "Residential"
df$type[df$type %in% "Industrial Area"] <- "Industrial"
df$type[df$type %in% "Industrial Areas"] <- "Industrial"
df$type[df$type %in% "RIRUO"] <- "Others"
df$type[df$type %in% "Sensitive"] <- "Others"
df$type[df$type %in% "Sensitive Areas"] <- "Others"
df$type[df$type %in% "Sensitive Area"] <- "Others"
df$type[is.na(df$type)]= "Others"
```


```{r plot Type2}
plotdata <- df %>%
  count(type) %>%
  mutate(pct = n / sum(n),
         pctlabel = paste0(round(pct*100), "%"))

p1<-ggplot(plotdata, aes(x = reorder(type, n), y=pct)) +
  geom_bar(stat = "identity", fill = "lightgreen") +
  geom_text(aes(label = pctlabel), vjust = -0.25) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_y_continuous(labels = percent) +
  labs(y = "Percentage", x="Area Type", title = "Percentage of Recording From Each Type of Area")
p1
```

Now there is only 3 groups in area type.

### 4. Numerical Vairable - Sulfur dioxide (SO2), Nitrogen dioxide (nO2), Respirable Suspended Particulate Matter (rspm), Suspended particulate matter (spm), Fine particulate matter (pm2.5)
```{r plot numeric}
plot1=ggplot(df, aes(x = so2)) +
  geom_histogram(binwidth=0.1, breaks= seq(0,100), colour="black", fill = "lightgreen")
plot2=ggplot(df, aes(x = no2)) +
  geom_histogram(binwidth=1, breaks= seq(0,200),colour="black", fill = "lightgreen")
plot3=ggplot(df, aes(x = rspm)) +
  geom_histogram(binwidth=100,  breaks= seq(0,500), fill = "lightgreen")
plot4=ggplot(df, aes(x = spm)) +
  geom_histogram(binwidth=100, breaks= seq(0,1000) ,fill = "lightgreen")
plot5=ggplot(df, aes(x = pm2_5)) +
  geom_histogram(binwidth=0.5, breaks= seq(0,300), colour="black", fill = "lightgreen")
grid.newpage()
vplayout <- function(x, y) viewport(layout.pos.row = x, layout.pos.col = y)
pushViewport(viewport(layout = grid.layout(5, 1)))
print(plot1, vp = vplayout(1, 1))
print(plot2, vp = vplayout(2, 1))
print(plot3, vp = vplayout(3, 1))
print(plot4, vp = vplayout(4, 1))
print(plot5, vp = vplayout(5, 1))
```

There are 34646 rows of missing value in "so2", 16233 rows of missing value in “no2”, 40222 rows of missing value in “rspm”, 237387 rows of missing value in “spm”, 426428 rows of missing value in “pm2_5”.

We can observe that all so2, no2, rspm, spm and pm2_5 is right skewed, data scattered around lower value.


## Creating Clean Data set for multivariate EDA


```{r plot subset2}
df_c=df
data_c_path = paste0(datadir, "/data_c.csv")

df_c$pm2_5=NULL
df_c$date=NULL
head(df_c)
```

We dropped pm2.5 because it is the target variable and it is only available for last 2 year. 
We dropped date because clustering model no need time variable. 

### Cleaning Missing Values

```{r plot subset2 missing value 1}
for(i in 1:7){
  x=sum(is.na(df_c[i]))
  print(paste(names(df_c[i]),x))}
```

so2,no2,rspm and spm have missing values

```{r plot subset2 cleaning 1}
df_c$so2[is.na(df_c$so2)]= mean(df_c$so2, na.rm = TRUE)
df_c$no2[is.na(df_c$no2)]= mean(df_c$no2, na.rm = TRUE)
df_c$rspm[is.na(df_c$rspm)]= mean(df_c$rspm, na.rm = TRUE)
df_c$spm[is.na(df_c$spm)]= mean(df_c$spm, na.rm = TRUE)
df_c <- df_c %>% na.omit(df_c)

for(i in 1:7){
  x=sum(is.na(df_c[i]))
  print(paste(names(df_c[i]),x))}

```

We mutate missing value in numerical variable using mean. 3 missing value for location, we just drop. 
There is no more missing values in the dataset, it is ready to export. 

```{r subset2 stat}
head(df_c)
str(df_c)
```

### Export Subset if needed

```{r export subset2 csv}
#data_c_path = paste0(datadir, "/data_c.csv")
#write.csv(df_c, data_c_path, row.names=FALSE)
```



### Exploratory Data Analysis - Multivariate  

### 1. correlation
```{r plot correlation}
#pairs(~ so2 + no2 + rspm + spm, data=df_c, col = 'blue')
#plot(df_c)
knitr::include_graphics("plot correlation-1.png")
knitr::include_graphics("plot correlation-2.png")
```

so2 and no2 seem to have slightly positive relationship while the others variables seem like having poor relationship. 


### 2. Bivarite plot

#### Numerical variables with state
```{r plot so2 state}
plotdata <- df_c %>%
  group_by(state) %>%
  summarize(mean_1 = mean(so2))
ggplot(plotdata, aes(x = reorder(state, mean_1), y = mean_1)) +
  geom_bar(stat = "identity", fill = "cornflowerblue") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  labs(title = "So2 by state", y = "Mean of SO2", x ="State")

plotdata <- df_c %>%
  group_by(state) %>%
  summarize(mean_1 = mean(no2))
ggplot(plotdata, aes(x = reorder(state, mean_1), y = mean_1)) +
  geom_bar(stat = "identity", fill = "cornflowerblue") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  labs(title = "No2 by state", y = "Mean of NO2", x ="State")

plotdata <- df_c  %>%
  group_by(state) %>%
  summarize(mean_1 = mean(rspm))
ggplot(plotdata, aes(x = reorder(state, mean_1), y = mean_1)) +
  geom_bar(stat = "identity", fill = "cornflowerblue") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  labs(title = "RSPM by state", y = "Mean of RSPM", x ="State")

plotdata <- df_c  %>%
  group_by(state) %>%
  summarize(mean_1 = mean(spm))
ggplot(plotdata, aes(x = reorder(state, mean_1), y = mean_1)) +
  geom_bar(stat = "identity", fill = "cornflowerblue") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  labs(title = "SPM by state", y = "Mean of SPM", x ="State")

```

Jharkhand have the highest SO2 concentration in the air. 
West Bengal have the highest NO2 concentration in the air.
Punjab have the highest RSPM index.
Delhi have the highest SPM index.

#### Numerical variables with type
```{r plot so2 type}
plotdata <- df_c %>%
  group_by(type) %>%
  summarize(mean_1 = mean(so2))
plot1=ggplot(plotdata, aes(x = reorder(type, mean_1), y = mean_1)) +
  geom_bar(stat = "identity", fill = "cornflowerblue") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = "So2 by area type", y = "Mean of SO2", x ="Area Type")

plotdata <- df_c %>%
  group_by(type) %>%
  summarize(mean_1 = mean(no2))
plot2=ggplot(plotdata, aes(x = reorder(type, mean_1), y = mean_1)) +
  geom_bar(stat = "identity", fill = "cornflowerblue") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = "No2 by area type", y = "Mean of NO2", x ="Area Type")

plotdata <- df_c %>%
  group_by(type) %>%
  summarize(mean_1 = mean(rspm))
plot3=ggplot(plotdata, aes(x = reorder(type, mean_1), y = mean_1)) +
  geom_bar(stat = "identity", fill = "cornflowerblue") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = "RSPM by area type", y = "Mean of RSPM", x ="Area Type")

plotdata <- df_c %>%
  group_by(type) %>%
  summarize(mean_1 = mean(spm))
plot4=ggplot(plotdata, aes(x = reorder(type, mean_1), y = mean_1)) +
  geom_bar(stat = "identity", fill = "cornflowerblue") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = "SPM by area type", y = "Mean of SPM", x ="Area Type")
grid.newpage()
pushViewport(viewport(layout = grid.layout(2, 2)))
print(plot1, vp = vplayout(1, 1))
print(plot2, vp = vplayout(1, 2))
print(plot3, vp = vplayout(2, 1))
print(plot4, vp = vplayout(2, 2))

```

Industrial area have highest So2 concentration, No2 concentration, RSPM index and SPM index. 



##  Create Subset
### Create Subset for Time Series Regression Model
From the original data set, we also produce a clean data for time series regression purposes. 
The goal is to create a data set for predicting pm2.5 using the data from year 2014 and 2015. 
```{r plot subset1}
data=subset(df, !is.na(pm2_5))
head(data)
str(data)
```

There is only 9314 rows that have pm2.5 value.  

### Cleaning Missing Values

```{r plot subset missing value 1}
for(i in 1:9){
  x=sum(is.na(data[i]))
  print(paste(names(data[i]),x))}
```

so2,no2,rspm have missing values. spm is blank. 

```{r plot subset cleaning 1}
data$so2[is.na(data$so2)]= mean(data$so2, na.rm = TRUE)
data$no2[is.na(data$no2)]= mean(data$no2, na.rm = TRUE)
data$rspm[is.na(data$rspm)]= mean(data$rspm, na.rm = TRUE)
data$spm=NULL

for(i in 1:8){
  x=sum(is.na(data[i]))
  print(paste(names(data[i]),x))}
```

There is no missing value now and we can export this subset out for further enhancement such as visualization, modifications and modelling depending on the requirement of time series modelling. 


### Rearrange According To Date

```{r rearrange}
data$date<-as.Date(data$date, "%Y-%m-%d")
data=data[(order(data$date,decreasing=FALSE)),]
```

### Export Subset if needed

```{r export subset1 csv}
#write.csv(data,"data_ts.csv", row.names=FALSE)
```


### Time Series Plot 

```{r}
#check the data of noPmNA
table(data$state)
```


```{r}
#split the dataset
splitByState <- split(data, data$state)
str(splitByState)
```

```{r}
library(ggplot2)

for (i in 1:length(splitByState)){
  loopdata<-splitByState[[i]]
  #print(loopdata)
  #print(as.character(names(splitByState[i])))
  #draw graph
  print(ggplot() +geom_line(data = loopdata,aes(x = date,y = pm2_5,colour = "pm2_5"),size=1) +
  geom_line(data = loopdata,aes(x = date,y = so2,colour = "so2"),size=1) +
  geom_line(data = loopdata,aes(x = date,y = no2,colour = "no2"),size=1) +
  geom_line(data = loopdata,aes(x = date,y = rspm,colour = "rspm"),size=1) +
  ggtitle(paste("State:",as.character(names(splitByState[i])))) +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_colour_manual("",values = c("pm2_5" = "red","so2"="green","no2"="blue","rspm"="yellow"))+
  xlab("Date")+ylab("Pollution"))
}


```

## Modelling & Results & Evaluation

### Time series

Since the dataset can be listed in a series of data points ordered in time, we decided to proceed with time series as our analysis. The independent variable is usually associated with time and the dependent variable is the target of the prediction. Due to the fact that there is more than one time-dependent variable, we will utilize the Multivariate Time series which the prediction not only depends on the past values but also dependent on other variables. 

Since there are many states, location and type of development, we would like to focus on Madhya Pradesh regardless of location and type of development when conducting the time series modelling. We continue the data preparation for that purpose. 

Thus we create a separate data frame for state Madhya Pradesh.

```{r}
Madhya_Pradesh = data[which (data$state == 'Madhya Pradesh'), ] 
```

Remove other variables which are location and type
```{r}
Madhya_Pradesh = subset(data, select = -c(state, location, type))
```
Since there are repeating entries for the same date which may be due to location and type, we group the date by mean.

```{r}
Madhya_Pradesh$day <- floor_date(Madhya_Pradesh$date, "day")
Madhya_Pradesh = aggregate(cbind(so2,no2,rspm,pm2_5) ~ day, data = Madhya_Pradesh, FUN = mean, na.rm = TRUE)
```

Create a train and test set (test set is set for 30 days) for modelling and validation purpose.
```{r}
MP_train= Madhya_Pradesh[1:697, ]
MP_train=subset(MP_train,select = -c(day))
MP_test= Madhya_Pradesh[698:727, ]
```

Using ts() to convert the dataframe into a time series object. To utilize ts(), we might have to calculate the day in number for ts().

```{r}
#as.numeric(as.Date("2014-01-01") - as.Date("2014-01-01"))
MP_train=ts(MP_train,start = c(2014,0),frequency = 365)
```

We replot the time series graph for training set of Madhya Pradesh.

```{r}
autoplot(MP_train) +
  ggtitle("Time Series Plot of the Madhaya Pradesh Time-Series") +
  theme(plot.title = element_text(hjust = 0.5))
```

Next, we proceed to the modelling portion. 
First, we have to conduct the stationarity test as plotting a graph sometimes may not be adequate to determine whether the variables are stationary. We use Augmented Dickey-Fuller (ADF) Test in R to determine the stationarity of the data.
```{r}
apply(MP_train, 2, adf.test)
```

Since all data is stationary, we may proceed to modelling without differencing. We will utilize the Vector Autoregression model (VAR) to capture the relationship within a multivariate time series. Next, we will determine the lag p for the VAR(p) model. 
```{r}
VARselect(MP_train, 
          type = "none", #type of deterministic regressors to include. We use none because the time series was made stationary using differencing above. 
          lag.max = 20) #highest lag order n= 10
```

The highest lag according to the lag selection is 10. We proceed by creating the model.
```{r}
var.a <- vars::VAR(MP_train,
                   lag.max = 10, #highest lag order for lag length selection according to the choosen ic
                   ic = "AIC", #information criterion
                   type = "none") #type of deterministic regressors to include
```

The result summaries of the VAR model fitting function. 
```{r}
summary(var.a)
```

We will use Granger test for causality where the null hypothesis is the lagged x-values do not explain the variation in y. In other words, it assumes that independent variable does not cause the dependent variable. All variable of multivariate time series have to be stationary for causality function to give reliable results.
```{r}
causality(var.a, #VAR model
          cause = c("pm2_5")) #dependent variable. If not specified then first column of x is used. Multiple variables can be used. 
```
The results shows that the null hypothesis is rejected and the independent variables can explain the PM 2.5.

Since the model is adequate, we proceed with forecasting and plot the forecast.
```{r}
fcast = predict(var.a, n.ahead =30) # we forecast over a month
par(mar = c(2.5,2.5,2.5,2.5))
plot(fcast)
```

We continue with evaluation.
```{r}
f.val= fcast$fcst$pm2_5[,1]
a.val= MP_test[['pm2_5']] # the accuracy requires numeric vector only. 
accuracy(f.val,a.val)
```

### Clustering
Besides time series modelling, we also do a clustering to identify cities (location) with similar air quality. We cluster them by using only the latest 1 year (2015-01-01 to 2015-12-31) of data, with the mean value of numerical variables (SO2, NO2, RSPM, SPM, PM2.5) as the features.

First we import relevant library. We then filter the recent data and obtain the features mentioned above:
```{r message=FALSE}
library(cluster)
library(lubridate)

start_date<- ymd("2015-01-01")
rec_clus_data<- df[df$date > start_date, ]

### remove rows with missing location
rec_clus_data<- rec_clus_data[!is.na(rec_clus_data$location), ]

loc_data<- rec_clus_data %>% group_by(location) %>%
  summarise(mean_so2 = mean(so2, na.rm=TRUE),
            mean_no2 = mean(no2, na.rm=TRUE),
            mean_rspm = mean(rspm, na.rm=TRUE),
            mean_spm = mean(spm, na.rm=TRUE),
            mean_pm2_5 = mean(pm2_5, na.rm=TRUE)
  ) %>% data.frame()

head(loc_data)
```
Next we check and handle the missing values.
```{r}
num_loc = nrow(loc_data)

for (col in colnames(loc_data) ){
  num_na<- sum(is.na(loc_data[col]))
  perc_na<- round(100*num_na/num_loc, digits=2)
  print(paste(col, num_na, perc_na))
}
```

We see that SPM (100%) and PM2.5 (75.2%) have very large amount of missing values. We can only drop these features as imputing them will introduce large bias in the clustering model. \n
For SO2 and NO2, we will impute using mean value.

```{r}
loc_data$mean_so2[is.na(loc_data$mean_so2)]= mean(loc_data$mean_so2, na.rm = TRUE)
loc_data$mean_no2[is.na(loc_data$mean_no2)]= mean(loc_data$mean_no2, na.rm = TRUE)

#### set location as row names
rownames(loc_data)<- loc_data$location

#### drop unnecessary columns
clean_loc_data<- loc_data %>% dplyr::select(-c(mean_spm, mean_pm2_5, location))

head(clean_loc_data)
```

Before clustering the data, we need to scale the features so that their magnitude are of the same order.

```{r}
scaled_loc_data<- clean_loc_data
for (mean_col in colnames(scaled_loc_data)){
 scaled_loc_data[mean_col]<- scale(scaled_loc_data[mean_col], center=TRUE, scale=TRUE)
}
```

Now we can do clustering. We use the elbow method to obtain a suitable number of clusters, k.

```{r}
max_k<- 20
wcss<- rep(NA, max_k-1)

for (k in c(2:max_k)){
  k_clus<- kmeans(scaled_loc_data, centers = k, nstart = 10)
  wcss[k-1]<- k_clus$tot.withinss
}

wcss_df<- data.frame(k=c(2:max_k), wcss = wcss)
wcss_fig<- wcss_df %>% ggplot(aes(x=k, y=wcss)) + 
  geom_line() + geom_point()

print(wcss_fig)
```

Here, we see that at around k=8 the Within Cluster Sum of Squared (WCSS) value decreases slowly. Thus we will pick optimal k as 8 to do the clustering.

```{r}
best_k<- 8

clus_loc<- kmeans(scaled_loc_data, centers = scaled_loc_data[1:best_k,], nstart = 10)
clus_grp<- data.frame(clus_loc$cluster) %>% setNames("cluster")
merged_res<- merge(clean_loc_data, clus_grp, by ='row.names', all=TRUE)
merged_res$cluster<- as.factor(merged_res$cluster)

### center of each cluster
center_data<- merged_res %>% group_by(cluster) %>%
  summarise(num_city = n(),
            cen_mean_so2 = mean(mean_so2, na.rm=TRUE),
            cen_mean_no2 = mean(mean_no2, na.rm=TRUE),
            cen_mean_rspm = mean(mean_rspm, na.rm=TRUE),
  ) %>% data.frame()

print(center_data)
```

The above table shows the centroid for each cluster. To better visualise the difference among the clusters, we can plot the box plot of each features for the clusters:

```{r}
clus_vis_so2<- merged_res %>% ggplot(aes(x=cluster, y=mean_so2)) +
  geom_boxplot()
print(clus_vis_so2)

clus_vis_no2<- merged_res %>% ggplot(aes(x=cluster, y=mean_no2)) +
  geom_boxplot()
print(clus_vis_no2)

clus_vis_rspm<- merged_res %>% ggplot(aes(x=cluster, y=mean_rspm)) +
  geom_boxplot()
print(clus_vis_rspm)
```

From the plot, we see that cities in cluster 6, 7 and 8 have high values in all 3 features, which represents low air quality. Interestingly, these clusters have significantly high value in exactly 1 of the feature: cluster 6 is high in RSPM, cluster 7 in SO2 and cluster 8 in NO2.
For the others, cities in cluster 5 have the best air quality with lowest value in all 3 features. Cluster 2, 3, 4 have moderate value in all 3 features while cluster 1 has moderate value in SO2 and NO2 but with high RSPM.

## Discussion ()

Upon comparing the concentrations of pollutants in various cities within India 
discovered that Maharashtra have most observations among other cities; in terms of type of area residential areas has the highest percentage of pollutants in air:

1. SO2 concentration of Mizoram was found to be lowest and highest was of Uttaranchal.
2. NO2 concentration of Mizoram was found to be lowest and highest was of West Bengal.
3. RSPM concentration was found critical in all cities among which low critical level was found in Sikkim and extreme critical levels were found in Uttar Pradesh and Dehli.
4. SPM concentration was found very critical in all in all cities among which low critical level was found in Sikkim and extreme critical levels were found in Delhi.
5. Mostly concentration of pollutants was found to be higher industrial areas.

## Conclusion (Puvee)

From the given data it can be concluded that level of RSPM and PM2.5 are extremely higher in all cities of India. Furthermore, Jharkhand have the highest SO2 concentration in the air. West Bengal have the highest NO2 concentration in the air. Punjab have the highest RSPM index. Delhi have the highest SPM index.The major cause of generation of pollutants was similar across the states of India which was residential area. By carrying out exploratory data analysis, creating time series regression model and clustering technique able to visualize the condition of air quality in India deeply in different circumstances.Furthermore, the collected data can be utilized to model various pollutant behavior scenarios in the context of changing air quality policies or pollution generating patterns.Hence, the government of India should implement more efforts to make air quality monitoring a national priority by raising awareness and enforcing key laws and regulations to reduce pollution levels in the air.
